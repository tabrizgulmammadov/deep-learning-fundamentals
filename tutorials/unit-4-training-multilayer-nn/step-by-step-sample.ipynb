{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe2bc3a-8dc3-4ba1-9dee-6477568dc04f",
   "metadata": {},
   "source": [
    "## 1) One-Hot encoding in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed2b958a-5218-4035-b9f7-ec0822f683a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb201ea-ca58-46da-abfb-082dfc64e18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([0, 2, 2, 1])\n",
    "y_onehot = F.one_hot(y)\n",
    "y_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda7475d-329d-412a-81ad-4838c476f367",
   "metadata": {},
   "source": [
    "## 2) Net inputs (logits) ad Softmax activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f509f7a-26f1-4224-81ad-d31afe7edddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7162, 0.1766, 0.1071],\n",
       "        [0.1394, 0.1702, 0.6904],\n",
       "        [0.0229, 0.5613, 0.4158],\n",
       "        [0.1940, 0.7866, 0.0194]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_inputs = torch.tensor([[1.5, 0.1, -0.4],\n",
    "                           [0.5, 0.7, 2.1],\n",
    "                           [-2.1, 1.1, 0.8],\n",
    "                           [1.1, 2.5, -1.2]])\n",
    "activations = torch.softmax(net_inputs, dim=1)\n",
    "activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adecbee-5418-413f-98ec-38a6e0e09b42",
   "metadata": {},
   "source": [
    "## 3) Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552a936c-242b-4937-a591-1345ecfc45a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4555)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def manual_cross_entropy(net_inputs, y):\n",
    "    activations = torch.softmax(net_inputs, dim=1)\n",
    "    y_onehot = F.one_hot(y)\n",
    "    train_losses = - torch.sum(torch.log(activations) * (y_onehot), dim=1)\n",
    "    avg_loss = torch.mean(train_losses)\n",
    "    return avg_loss\n",
    "\n",
    "manual_cross_entropy(net_inputs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e15ff4d2-64c5-41e5-bcbf-5269ced0c6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4555)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y = torch.tensor([0, 2, 2, 1])\n",
    "# y_onehot = F.one_hot(y)\n",
    "\n",
    "net_inputs = torch.tensor([[1.5, 0.1, -0.4],\n",
    "                           [0.5, 0.7, 2.1],\n",
    "                           [-2.1, 1.1, 0.8],\n",
    "                           [1.1, 2.5, -1.2]])\n",
    "# activations = torch.softmax(net_inputs, dim=1)\n",
    "\n",
    "F.cross_entropy(net_inputs, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
