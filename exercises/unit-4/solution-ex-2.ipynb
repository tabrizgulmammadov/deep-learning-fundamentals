{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71bce70-9dc3-448b-9f9a-8896e83b6d09",
   "metadata": {},
   "source": [
    "# Implementing a Multilayer Perceptron (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b48fc7-4f46-4d5a-8558-cd06892aaa27",
   "metadata": {},
   "source": [
    "## 1) Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f5a9a-b3ee-424b-ab02-4371f49bd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install numpy pandas matplotlib --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7b3b8-9092-4b37-8b7f-57362be611ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd2077-ba5c-4ab5-95fc-6ee4d8a9f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fa295-5c62-4888-bcf8-d07d6a7afc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,matplotlib,torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9549676-2fa5-41a7-bbb9-ce03f5797c34",
   "metadata": {},
   "source": [
    "## 2) Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002ad95-a1f7-4c33-826a-4a45944f2687",
   "metadata": {},
   "source": [
    "- MNIST website: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609024c-3eae-4ad5-8cb8-b95b403b7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53652f7f-1327-4992-a78a-345921eeb854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, kind, transform=None):\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images, self.labels = load_mnist(data_dir, kind=kind)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        img = torch.tensor(img).to(torch.float32)\n",
    "        img = img/255.\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "train_dataset = MyDataset(data_dir=\"data/fashion\", kind=\"train\")\n",
    "test_dataset = MyDataset(data_dir=\"data/fashion\", kind=\"t10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6661307a-6220-48d5-b965-4cd36e29e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78adc94e-5418-4aac-9a82-9a9cbf8fc688",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765adcf0-9147-434b-917a-f6d736a7117e",
   "metadata": {},
   "source": [
    "### Create a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a42a2-cd46-46cf-ba93-d3f2f232f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "torch.manual_seed(1)\n",
    "train_dataset, val_dataset = random_split(train_dataset, lengths=[55000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e4a70-55b3-4fb0-b28d-b0fddd193fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50db02-3696-4f86-b149-74baabeec6c4",
   "metadata": {},
   "source": [
    "## 3) Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971389a7-5424-4141-a3ee-9399eebbbb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class PyTorchMLP(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.all_layers = torch.nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(num_features, 50),\n",
    "            torch.nn.ReLU(),\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(50, 25),\n",
    "            torch.nn.ReLU(),\n",
    "            # output layer\n",
    "            torch.nn.Linear(25, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        logits = self.all_layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc16a0-ec59-4c54-a209-0a5e22406287",
   "metadata": {},
   "source": [
    "## 4) The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de213fc-48b0-4f7c-af9e-8e2da068e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "\n",
    "    for idx, (features, labels) in enumerate(dataloader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return correct / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcaa2b1-4019-4128-9ff5-6a966c3abdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = PyTorchMLP(num_features=784, num_classes=10)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "loss_list = []\n",
    "train_acc_list, val_acc_list = [], []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "\n",
    "        logits = model(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if not batch_idx % 250:\n",
    "            ### LOGGING\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "                f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "                f\" | Train Loss: {loss:.2f}\"\n",
    "            )\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    train_acc = compute_accuracy(model, train_loader)\n",
    "    val_acc = compute_accuracy(model, val_loader)\n",
    "    print(f\"Train Acc {train_acc*100:.2f}% | Val Acc {val_acc*100:.2f}%\")\n",
    "    train_acc_list.append(train_acc)\n",
    "    val_acc_list.append(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d5821-7c8d-46b5-9e7d-02e72cac2acc",
   "metadata": {},
   "source": [
    "## 5) Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27538c8d-61bc-47b0-8289-b6aab4aa16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = compute_accuracy(model, train_loader)\n",
    "val_acc = compute_accuracy(model, val_loader)\n",
    "test_acc = compute_accuracy(model, test_loader)\n",
    "\n",
    "print(f\"Train Acc {train_acc*100:.2f}%\")\n",
    "print(f\"Val Acc {val_acc*100:.2f}%\")\n",
    "print(f\"Test Acc {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f8499-3191-4f78-b2d4-82daba9b9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_plotting import plot_training_loss\n",
    "\n",
    "plot_training_loss(minibatch_loss_list=loss_list,\n",
    "                   num_epochs=num_epochs,\n",
    "                   iter_per_epoch=len(loss_list)//num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d4519-b7a2-4382-90d0-a0dce2ee608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_plotting import plot_accuracy\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list, valid_acc_list=val_acc_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
